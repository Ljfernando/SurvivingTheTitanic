---
title: "TitanicSurvival"
author: "Lance J. Fernando"
---


First lets import the training and testing sets
```{r}
tit_test <- read.csv("/Users/lancefernando/Desktop/DataMining/PythonProjects/Titanic/titanic_test.csv", header = TRUE)
tit_train <- read.csv("/Users/lancefernando/Desktop/DataMining/PythonProjects/Titanic/titanic_train.csv", header = TRUE)
head(tit_train)
```

Notice that all passengers have a title after their surname. In order to extract this, lets split up each name observation using [,.] as our delimeter. With this we can extract titles.
```{r}
names.split <- strsplit(as.character(tit_train$Name), "[,.]")
test.names.split <- strsplit(as.character(tit_test$Name), "[,.]")

title <- rep(NA, length(names.split))
test.title <- rep(NA, length(test.names.split))

for(i in 1:length(names.split)){
  title[i] <- trimws(names.split[[i]][2])
}

for(i in 1:length(test.names.split)){
  test.title[i] <- trimws(test.names.split[[i]][2])
}
table(title)
table(test.title)
```

Lets anaylze the survival rate based on Sex. 
```{r}
table(Survived = tit_train$Survived, Sex = tit_train$Sex)
barplot(table(tit_train$Survived, tit_train$Sex), legend = c('Died', 'Survived'),
        xlab = 'Sex', ylab = 'Frequency', main = 'Female vs Male Survival Rate')
```

Age is an important feature to include however many observations are missing from that column. In order to extract the essence of age out of each passenger, we can use their title along with other features.
Since mostly women survived, lets anaylze which among those women were more likely to make it out.
```{r}
table(Survived = tit_train$Survived[tit_train$Sex == 'female'], title[tit_train$Sex == 'female'])
```

Lets change the Sex values to 0 and 1 for female and male respectively.
```{r}
tit_train$Sex <- ifelse(tit_train$Sex == "male", 1, 0)
tit_test$Sex <- ifelse(tit_test$Sex == "male", 1, 0)
```
Women with titles 'Miss' and 'Mrs' occur more often so lets dive further into that data.
We can easily categorize women with the title of 'Mrs' to be married so lets make that into a feature. In addition, the title of 'Master' for men means that they are under the age of 18. Lets also create that feature.
```{r}
marrWom <- rep(0, nrow(tit_train))
marrWom.test <- rep(0,nrow(tit_test))
marrWom <- ifelse(title == "Mrs", 1, 0)
marrWom.test <- ifelse(test.title == "Mrs", 1, 0)
tit_train$marrWom <- marrWom
tit_test$marrWom <- marrWom.test

isBoy <- rep(0, nrow(tit_train))
isBoy.test <- rep(0,nrow(tit_test))
isBoy <- ifelse(title == "Master", 1, 0)
isBoy.test <- ifelse(test.title == "Master", 1, 0)

tit_train$isBoy <- isBoy
tit_test$isBoy <- isBoy.test
```

Lets analyze the age range for those with the title of 'Miss' or 'Ms'. We can also include the column regarding the number of Siblings/Spouses and Parents/Children.
```{r}
barplot(table(tit_train$Parch[title=="Miss"],tit_train$Age[title == "Miss"]),
        legend = c("0 Parents/Children", "1 Parent/Child", "2 Parents/Children"),
        xlab = "Age", ylab = "Frequency", main = "Ages of those titled 'Miss'")

barplot(table(tit_train$SibSp[title=="Miss"],tit_train$Age[title == "Miss"]),
        legend = c("0 Siblings/Spouses", "1 Sib/Spouse", "2 Sib/Spouse",
                   "3 Sib/Spouse", "4 Sib/Spouse", "5 Sib/Spouse", "8 Sib/Spouse"),
        col = c("darkslategrey", "darkslategray4", "darkslategray3", "darkslategray1",
                "goldenrod4", "goldenrod3", "goldenrod1"),
        xlab = "Age", ylab = "Frequency", main = "Ages of those titled 'Miss'")
mean(tit_train$Age[title == 'Miss' | title == 'Ms'], na.rm = TRUE)

```

The average age for 'Miss'/'Ms' is 21.8. In addition, those that are older tend to have smaller family sizes; and more importantly travel alone. So using this information we can create another feature that will categorize 'Miss'/'Ms' whether they are under or over this mean age.
```{r}
youngFem <- rep(0, nrow(tit_train))
youngFem.test <- rep(0,nrow(tit_test))
miss <- c(which(title == 'Miss'), which(title == 'Ms'))
miss.test <- c(which(test.title == 'Miss'), which(test.title == 'Ms'))
for(i in miss){
  if(is.na(tit_train$Age[i])){
    if(tit_train$SibSp[i] >= 1 || tit_train$Parch[i] >= 1)
      youngFem[i] <- 1
  }
  else if(tit_train$Age[i] <= 22)
    youngFem[i] <- 1
}
for(i in miss.test){
  if(is.na(tit_test$Age[i])){
    if(tit_test$SibSp[i] >= 1 || tit_test$Parch[i] >= 1)
      youngFem.test[i] <- 1
  }
  else if(tit_test$Age[i] <= 22)
    youngFem.test[i] <- 1
}

tit_train$youngFem <- youngFem
tit_test$youngFem <- youngFem.test
```

Lets also add a variable for family size. We add 1 to account for the passengers themselves as well.
```{r}
tit_train$famSize <- tit_train$SibSp + tit_train$Parch + 1
tit_test$famSize <- tit_test$SibSp + tit_test$Parch + 1
```

In the test set there seems to be an NA value for Fare. The passenger is of Pclass 3. Lets analyze how Pclass and Fare are correlated and give that passenger the mean Fare price for those of Pclass 3.
```{r}
missing.Fare <- which(is.na(tit_test$Fare))
tit_test[missing.Fare,]
cor(tit_train$Fare, tit_train$Pclass)
tit_test$Fare[missing.Fare] <- mean(tit_train$Fare[tit_train$Pclass == 3])
```

Where people embarked from may turn out to be a significant feature. Analyzing the levels there are two passengers that have missing embark values. With a simple google search, these passengers boarded the Titanic at Southampton or 'S'. Lets just input that into our dataset
```{r}
levels(tit_train$Embarked)
levels(tit_test$Embarked)
missing.Embarked <- which(tit_train$Embarked == "")
tit_train$Embarked[missing.Embarked] <- "S"
tit_train[missing.Embarked,]
```
 
Now lets analyze the survival rate of each boarding station and create a new feature for each one.
```{r}
table(tit_train$Survived, tit_train$Embarked)
tit_train$Embarked.S <- ifelse(tit_train$Embarked == 'S', 1, 0)
tit_train$Embarked.Q <- ifelse(tit_train$Embarked == 'Q', 1, 0)
tit_train$Embarked.C <- ifelse(tit_train$Embarked == 'C', 1, 0)

tit_test$Embarked.S <- ifelse(tit_test$Embarked == 'S', 1, 0)
tit_test$Embarked.Q <- ifelse(tit_test$Embarked == 'Q', 1, 0)
tit_test$Embarked.C <- ifelse(tit_test$Embarked == 'C', 1, 0)


```

Lets also take a look at the cabin feature. This may or may not be important in our final model but it will not hurt to extract info out of it. We will create a feature for each cabin. Those that do not have their cabin labeled explicitly will get a 'U' for unknown.
```{r}
tit_train$cab <- ifelse(tit_train$Cabin == "" | tit_train$Cabin == "T", "U", substr(tit_train$Cabin,1,1))
tit_test$cab <- ifelse(tit_test$Cabin == "" | tit_test$Cabin == "T", "U", substr(tit_test$Cabin,1,1))

table(tit_train$Survived, tit_train$cab)

tit_train$cab.A <- ifelse(tit_train$cab == 'A', 1, 0)
tit_train$cab.B <- ifelse(tit_train$cab == 'B', 1, 0)
tit_train$cab.C <- ifelse(tit_train$cab == 'C', 1, 0)
tit_train$cab.D <- ifelse(tit_train$cab == 'D', 1, 0)
tit_train$cab.E <- ifelse(tit_train$cab == 'E', 1, 0)
tit_train$cab.F <- ifelse(tit_train$cab == 'F', 1, 0)
tit_train$cab.G <- ifelse(tit_train$cab == 'G', 1, 0)
tit_train$cab.U <- ifelse(tit_train$cab == 'U', 1, 0)

tit_test$cab.A <- ifelse(tit_test$cab == 'A', 1, 0)
tit_test$cab.B <- ifelse(tit_test$cab == 'B', 1, 0)
tit_test$cab.C <- ifelse(tit_test$cab == 'C', 1, 0)
tit_test$cab.D <- ifelse(tit_test$cab == 'D', 1, 0)
tit_test$cab.E <- ifelse(tit_test$cab == 'E', 1, 0)
tit_test$cab.F <- ifelse(tit_test$cab == 'F', 1, 0)
tit_test$cab.G <- ifelse(tit_test$cab == 'G', 1, 0)
tit_test$cab.U <- ifelse(tit_test$cab == 'U', 1, 0)
```

Now that we have an abundance of features lets see what we have analyze their correlation to survival.
```{r}
head(tit_train[,c(2,3,5,7,8,10,c(13:19), c(21:27))])
cor(tit_train[,c(2,3,5,7,8,10,c(13:19), c(21:27))])
```

Lets start modeling. We will begin with logistic regression and validate our misclassification error rate using cross validation. In order to show how to script cross validation lets try it with a simple model using Pclass and Sex. We get a success rate of 78.5% which is not too bad. Remember we do not want to overfit our model on the training set because that would lead to a reduction of accuracy on the test set.
```{r}
attach(tit_train)

K = 5
folds <- sample(1:K, nrow(tit_train), replace = TRUE)
error <- rep(0, 5)

for(i in 1:K){
  log.fit <- glm(Survived~Pclass + Sex,
                 data = tit_train,
                 subset = which(folds != i),
                 family = binomial)
  log.train.probs <- predict(log.fit, newdata = tit_train[folds == i,], type = "response")
  log.train.preds <- ifelse(log.train.probs >= 0.5, 1, 0)
  error[i] <- mean(log.train.preds != Survived[folds == i])
}
print(paste('Error rate: ', mean(error)))
print(paste('Success rate: ', 1-mean(error)))

```

Now lets create a model using random forests. This is the model used to score 0.80383 and landed me at number 1076 on the leaderboard as of Tue, 03 Jan 2017 22:06:22. Notice that it does not utilize all the features we had created initially.
```{r}
library(randomForest)
set.seed(1)
rf.fit <- randomForest(factor(Survived) ~Pclass + Sex + famSize+
                         isBoy + youngFem + marrWom 
                       + Embarked.S + Embarked.C + Embarked.Q,
                       data = tit_train, mtry = 2, ntree = 15000, nodesize = 1,
                       importance = FALSE)
rf.pred.train <- predict(rf.fit, newdata = tit_train, type = "class")
print(paste('Success rate on training data: ', mean(rf.pred.train == tit_train$Survived)))

rf.pred.out <- predict(rf.fit, newdata = tit_test, type = "class")
```

Using our predictions from the model we can write it out to a csv file of choice. Simply run the method using the filename of choice as the parameter
```{r}
results <- data.frame(PassengerId = 892:1309, Survived = rf.pred.out)

write_results_csv <- function(filename){
  write.csv(results, filename, row.names = FALSE)
}
```


